@article{Roos2003,
author = {Roos, Ewa M. and Lohmander, L. Stefan},
journal = {Bio Med Central},
title = {{The knee injury and osteoarthritis outcome score (KOOS): from joint injury to osteoarthritis}},
year = {2003}
}
@incollection{Schmidt1989,
author = {Schmidt, R. F},
booktitle = {Human Physiology},
doi = {10.1007/978-3-642-73831-9_10},
isbn = {978-3-642-73831-9},
publisher = {Springer Berlin Heidelberg},
title = {{Nociception and Pain}},
year = {1989}
}
@incollection{Ghosh2010,
author = {Ghosh, Kanishka M. and Deehan, David J.},
booktitle = {Orthopaedic surgery: lower limb},
editor = {Wilkinson, Mark},
publisher = {Elsevier},
title = {{Soft tissue knee injuries}},
year = {2010}
}
@incollection{Schmidt2013,
author = {Schmidt, R. F},
booktitle = {Fundamentals of Sensory Physiology},
edition = {2},
isbn = {9783662011287},
publisher = {Springer Science {\&} Business Media},
title = {{Nociception and Pain}},
year = {2013}
}
@book{Swamynathan2017,
author = {Swamynathan, Manohar},
doi = {10.1007/978-1-4842-2866-1},
isbn = {978-1-4842-2865-4},
title = {{Mastering Machine Learning with Python in Six Steps}},
url = {http://link.springer.com/10.1007/978-1-4842-2866-1},
year = {2017}
}
@article{Petersen2013,
author = {Petersen, Wolf and Ellermann, Andree and Et.al.},
doi = {10.1097/01.blo.0000229284.45485.6c},
journal = {Clinical Orthopaedics and Related Research},
title = {{Patellofemoral Pain Syndrome}},
year = {2013}
}
@article{Crossley2016,
author = {Crossley, Kay M. and Callaghan, Michael J. and Et.al},
doi = {10.1136/bjsports-2015-h3939rep},
title = {{Patellofemoral pain}},
year = {2016}
}
@article{Crossley2015,
author = {Crossley, Kay M. and Callaghan, Michael J. and Et.al.},
doi = {10.1136/bmj.h3939},
title = {{Patellofemoral pain}},
year = {2015}
}
@article{Smith2015,
author = {Smith, T.O. and Drew, B.T. and Et.al.},
doi = {10.1002/14651858.CD010513.pub2.},
title = {{Knee orthoses for treating patellofemoral pain syndrome (review)}},
year = {2015}
}
@article{Maclachlan2017,
author = {Maclachlan, Liam R. and Collins, Natalie J. and Et.al},
doi = {10.1136-bjsports-2016-096705},
title = {{The psychological features of patellofemoral pain: a systematic review}},
year = {2017}
}
@book{Mehryar2012,
author = {Mehryar, Mohri and Afshin, Rostamizadeh and Ameet, Talwalka},
isbn = {9780262018258},
title = {{Foundations of Machine Learning}},
url = {https://ebookcentral.proquest.com/lib/aalborguniv-ebooks/reader.action?docID=3339482{\&}ppg=17{\#}},
year = {2012}
}
@book{Bengio2012,
author = {Bengio, Yoshua},
doi = {10.1007/978-3-642-35289-8_26},
isbn = {978-3-642-35289-8},
pages = {437--478},
title = {{Neural Networks: Tricks of the Trade: Second Edition}},
url = {http://dx.doi.org/10.1007/978-3-642-35289-8{\_}26},
year = {2012}
}
@article{Acquarelli2017,
abstract = {In this work we show that convolutional neural networks (CNNs) can be efficiently used to classify vibrational spectroscopic data and identify important spectral regions. CNNs are the current state-of-the-art in image classification and speech recognition and can learn interpretable representations of the data. These characteristics make CNNs a good candidate for reducing the need for preprocessing and for highlighting important spectral regions, both of which are crucial steps in the analysis of vibrational spectroscopic data. Chemometric analysis of vibrational spectroscopic data often relies on preprocessing methods involving baseline correction, scatter correction and noise removal, which are applied to the spectra prior to model building. Preprocessing is a critical step because even in simple problems using ‘reasonable' preprocessing methods may decrease the performance of the final model. We develop a new CNN based method and provide an accompanying publicly available software. It is based on a simple CNN architecture with a single convolutional layer (a so-called shallow CNN). Our method outperforms standard classification algorithms used in chemometrics (e.g. PLS) in terms of accuracy when applied to non-preprocessed test data (86{\%} average accuracy compared to the 62{\%} achieved by PLS), and it achieves better performance even on preprocessed test data (96{\%} average accuracy compared to the 89{\%} achieved by PLS). For interpretability purposes, our method includes a procedure for finding important spectral regions, thereby facilitating qualitative interpretation of results.},
author = {Acquarelli, Jacopo and van Laarhoven, Twan and Gerretzen, Jan and Tran, Thanh N. and Buydens, Lutgarde M.C. and Marchiori, Elena},
doi = {10.1016/j.aca.2016.12.010},
issn = {18734324},
journal = {Analytica Chimica Acta},
keywords = {Convolutional neural networks,Preprocessing,Vibrational spectroscopy},
pages = {22--31},
pmid = {28081811},
title = {{Convolutional neural networks for vibrational spectroscopic data analysis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0003267016314842},
volume = {954},
year = {2017}
}
@article{Hameed2016,
abstract = {In this paper, we propose a novel machine learning classifier by deriving a new adaptive momentum back-propagation (BP) artificial neural networks algorithm. The proposed algorithm is a modified version of the BP algorithm to improve its convergence behavior in both sides, accelerate the convergence process for accessing the optimum steady-state and minimizing the error misadjustment to improve the recognized patterns superiorly. This algorithm is controlled by the learning rate parameter which is dependent on the eigenvalues of the autocorrelation matrix of the input. It provides low error performance for the weights update. To discuss the performance measures of this proposed algorithm and the other supervised learning algorithms such as k-nearest neighbours (k-NN), Naive Bayes (NB), linear discriminant analysis (LDA), support vector machines (SVM), BP, and BP with adaptive momentum (PBPAM) have been compared in term of speed of convergence, Sum of Squared Error (SSE), and accuracy by implementing benchmark problem - XOR and seven datasets from UCI repository.},
author = {Hameed, Alaa Ali and Karlik, Bekir and Salman, Mohammad Shukri},
doi = {10.1016/j.knosys.2016.10.001},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Adaptive momentum,Back-propagation,Neural network,Supervised learning},
pages = {79--87},
title = {{Back-propagation algorithm with variable adaptive momentum}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705116303811?via{\%}3Dihub},
volume = {114},
year = {2016}
}
@book{Goodfellow2016,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
publisher = {MIT Press},
title = {{Deep Learning}},
url = {http://www.deeplearningbook.org},
year = {2016}
}
@article{Schmidhuber2015,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distin-guished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks. Preface This is the preprint of an invited Deep Learning (DL) overview. One of its goals is to assign credit to those who contributed to the present state of the art. I acknowledge the limitations of attempting to achieve this goal. The DL research community itself may be viewed as a continually evolving, deep network of scientists who have influenced each other in complex ways. Starting from recent DL results, I tried to trace back the origins of relevant ideas through the past half century and beyond, sometimes using " local search " to follow citations of citations backwards in time. Since not all DL publications properly acknowledge earlier relevant work, additional global search strategies were em-ployed, aided by consulting numerous neural network experts. As a result, the present preprint mostly consists of references. Nevertheless, through an expert selection bias I may have missed important work. A related bias was surely introduced by my special familiarity with the work of my own DL research group in the past quarter-century. For these reasons, this work should be viewed as merely a snapshot of an ongoing credit assignment process. To help improve it, please do not hesitate to send corrections and suggestions to juergen@idsia.ch.},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.7828v4},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {arXiv:1404.7828v4},
isbn = {0893-6080},
issn = {18792782},
journal = {Neural Networks},
keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning},
pages = {85--117},
pmid = {25462637},
title = {{Deep Learning in Neural Networks: An Overview}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
volume = {61},
year = {2015}
}
@article{LeCun2015,
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
journal = {Nature Insight Review},
pages = {436--444},
title = {{Deep Learning}},
url = {https://www.nature.com/nature/journal/v521/n7553/pdf/nature14539.pdf},
year = {2015}
}
@misc{Solutions2015,
author = {Solutions, Aglance},
title = {{Visual insight for clinical reasoning – Navigate Pain}},
url = {http://www.navigatepain.com/},
year = {2015}
}
@article{Jordan2015,
abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today's most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Jordan, M. I. and Mitchell, T. M.},
doi = {10.1126/science.aaa8415},
eprint = {arXiv:1011.1669v3},
isbn = {0036-8075, 0036-8075},
issn = {0036-8075},
journal = {Science},
number = {6245},
pages = {255--260},
pmid = {26185243},
title = {{Machine learning: Trends, perspectives, and prospects}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aaa8415},
volume = {349},
year = {2015}
}
@book{Nielsen2010,
abstract = {Begrebet machine learning, som p{\aa} dansk vel mest passende kan gengives med ”automatisk l{\ae}ring”, er baseret p{\aa} det s{\ae}rlige omr{\aa}de inden for datalogisk forskning, der hedder algo- ritmer kombineret med statistisk analyse. Det g{\aa}r ud p{\aa} at lade computeren l{\ae}re at genkende m{\o}nstre ud fra eksempler og data og vel at m{\ae}rke l{\ae}re mere end eksemplerne selv: P{\aa} basis af data kan computeren ogs{\aa} l{\ae}re at generalisere til nye eksempler og tr{\ae}ffe s{\aa}kaldt intelligente beslutninger.},
author = {Nielsen, Mads},
booktitle = {Diku},
isbn = {978-87-981270-5-5},
pages = {92--103},
publisher = {Datalogisk Institut},
title = {{Den digitale revolution – fort{\ae}llinger fra datalogiens verden}},
year = {2010}
}
@article{Grunnesjo2006,
author = {Grunnesj{\"{o}}, Marie},
doi = {10.1186/1471-2474-7-65},
title = {{The course of pain drawings during a 10-week treatment period in patients with acute and sub-acute low back pain}},
year = {2006}
}
@article{Briggs2010,
author = {Briggs, Emma},
title = {{Understanding the experience and physiology of pain}},
year = {2010}
}
@misc{IASP2012,
author = {IASP},
title = {{IASP Taxonomy}},
year = {2012}
}
@book{Martini2012,
author = {et. al. Martini, Frederic H.},
title = {{Anatomy {\&} Physology}},
year = {2012}
}
@article{Boudreau2017,
author = {Boudreau, Shellie A. and et.al. Kamavuako, E. N.},
doi = {10.1186/s12891-017-1521-5},
title = {{Distribution and symmetrical patellofemoral pain patterns as revealed by high-resolution 3D body mapping: a cross-sectional study}},
year = {2017}
}
@article{Bayam2017,
author = {Bayam, Levent and et.al. Arumilli, Rajendra},
doi = {10.1093/pm/pnw326},
title = {{Testing shoulder pain mapping}},
year = {2017}
}
@article{Younger2009,
author = {Younger, Jarred and Mackey, Sean},
title = {{Pain outcomes: A brief review of instruments and techniques}},
year = {2009}
}
@article{Boudreau2016,
author = {Boudreau, Shellie A. and et.al Badsberg, Susanne},
doi = {10.1097/AJP.0000000000000230},
title = {{Digital pain drawings: Assessing Touch-Screen Technology and 3D Body Schemas}},
year = {2016}
}
@article{Schott2010,
author = {Schott, Geoffrey D.},
doi = {10.1016/j.ejpain.2009.12.005},
title = {{The cartography of pain: The evolving contribution of pain maps}},
year = {2010}
}
